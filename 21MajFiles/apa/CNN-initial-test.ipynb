{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc39e4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:07<00:00, 270.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset generated. Splitting into train/val...\n",
      "Done! Final structure is:\n",
      "synthetic_squares/images/train/  (images for training)\n",
      "synthetic_squares/images/val/    (images for validation)\n",
      "synthetic_squares/labels/train/  (labels for training)\n",
      "synthetic_squares/labels/val/    (labels for validation)\n",
      "data.yaml written!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image, ImageEnhance\n",
    "\n",
    "# CONFIG\n",
    "output_dir = \"synthetic_squares\"\n",
    "img_dir = os.path.join(output_dir, \"images\")\n",
    "lbl_dir = os.path.join(output_dir, \"labels\")\n",
    "os.makedirs(img_dir, exist_ok=True)\n",
    "os.makedirs(lbl_dir, exist_ok=True)\n",
    "\n",
    "img_size = 224\n",
    "total_images = 2000           # Total images (across train/val)\n",
    "min_squares = 1\n",
    "max_squares = 3               # Up to N colored squares per image\n",
    "distractor_shapes = True      # Add circles/triangles for difficulty\n",
    "blur_prob = 0.3\n",
    "brightness_jitter = 0.25\n",
    "real_bg_prob = 0.4            # Use real backgrounds X% of the time\n",
    "\n",
    "colors = {\n",
    "    \"blue\":   ((255,  30,  30), 0),\n",
    "    \"red\":    ((30,  30, 255), 1),\n",
    "    \"orange\": ((0, 165, 255), 2),\n",
    "    \"yellow\": ((0, 255, 255), 3),\n",
    "    \"purple\": ((200,  80, 200), 4),\n",
    "    \"brown\":  ((19,  69, 139), 5)\n",
    "}\n",
    "class_names = list(colors.keys())\n",
    "\n",
    "backgrounds = [\n",
    "    (240,240,240), (255,255,255), (200,200,200), (160,160,160),\n",
    "    (220,200,170), (230,230,210)\n",
    "]\n",
    "\n",
    "# Optional: supply your own real image backgrounds (landscape, desk, etc)\n",
    "real_bg_folder = \"real_backgrounds\"\n",
    "real_bg_files = glob.glob(os.path.join(real_bg_folder, \"*.jpg\"))\n",
    "\n",
    "def make_background():\n",
    "    if random.random() < real_bg_prob and real_bg_files:\n",
    "        bg = Image.open(random.choice(real_bg_files)).resize((img_size, img_size)).convert(\"RGB\")\n",
    "        bg = np.array(bg)\n",
    "    else:\n",
    "        bg = np.full((img_size, img_size, 3), random.choice(backgrounds), dtype=np.uint8)\n",
    "        # Add noise\n",
    "        if random.random() < 0.4:\n",
    "            noise = np.random.normal(0, 10, (img_size, img_size, 3))\n",
    "            bg = np.clip(bg + noise, 0, 255).astype(np.uint8)\n",
    "    return bg\n",
    "\n",
    "def random_square_params():\n",
    "    cx = random.randint(int(0.2*img_size), int(0.8*img_size))\n",
    "    cy = random.randint(int(0.2*img_size), int(0.8*img_size))\n",
    "    size = random.randint(int(0.18*img_size), int(0.5*img_size))\n",
    "    \n",
    "    # MODIFIED: Apply perspective transform with primary x-direction squeeze\n",
    "    # and slight y-direction squeeze for more realistic perspective\n",
    "    x_squeeze = random.uniform(0.4, 1.0)  # Primary squeeze in x direction (1.0 = no squeeze)\n",
    "    y_squeeze = random.uniform(0.85, 1.0)  # Slight squeeze in y direction (1.0 = no squeeze)\n",
    "    \n",
    "    return cx, cy, size, x_squeeze, y_squeeze\n",
    "\n",
    "def apply_random_blur(img):\n",
    "    if random.random() < blur_prob:\n",
    "        ksize = random.choice([3,5,7])\n",
    "        img = cv2.GaussianBlur(img, (ksize,ksize), 0)\n",
    "    if random.random() < 0.15:\n",
    "        # Simulate motion blur\n",
    "        size = random.choice([5,9,15])\n",
    "        kernel_motion_blur = np.zeros((size, size))\n",
    "        kernel_motion_blur[int((size-1)/2), :] = np.ones(size)\n",
    "        kernel_motion_blur = kernel_motion_blur / size\n",
    "        img = cv2.filter2D(img, -1, kernel_motion_blur)\n",
    "    return img\n",
    "\n",
    "def apply_brightness(img):\n",
    "    if random.random() < brightness_jitter:\n",
    "        factor = random.uniform(0.7, 1.3)\n",
    "        pil_img = Image.fromarray(img)\n",
    "        enhancer = ImageEnhance.Brightness(pil_img)\n",
    "        img = np.array(enhancer.enhance(factor))\n",
    "    return img\n",
    "\n",
    "def random_distractor(img):\n",
    "    shape = random.choice([\"circle\",\"triangle\"])\n",
    "    color = tuple(np.random.randint(0,255,3).tolist())\n",
    "    thickness = random.choice([-1,2])\n",
    "    if shape == \"circle\":\n",
    "        cx, cy = random.randint(0,img_size), random.randint(0,img_size)\n",
    "        r = random.randint(15,50)\n",
    "        cv2.circle(img, (cx,cy), r, color, thickness)\n",
    "    elif shape == \"triangle\":\n",
    "        pts = np.random.randint(0,img_size, (3,2))\n",
    "        cv2.polylines(img, [pts], isClosed=True, color=color, thickness=thickness if thickness>0 else 2)\n",
    "        if thickness == -1:\n",
    "            cv2.fillPoly(img, [pts], color)\n",
    "    return img\n",
    "\n",
    "# --- Generation Loop ---\n",
    "print(\"Generating images...\")\n",
    "all_image_paths = []\n",
    "for i in tqdm(range(total_images)):\n",
    "    img = make_background()\n",
    "    label_lines = []\n",
    "    nsq = random.randint(min_squares, max_squares)\n",
    "    used_classes = random.sample(list(colors.keys()), nsq)\n",
    "    for cname in used_classes:\n",
    "        bgr, classid = colors[cname]\n",
    "        cx, cy, size, x_squeeze, y_squeeze = random_square_params()\n",
    "        half = size / 2\n",
    "        \n",
    "        # MODIFIED: Create square with primary x-dimension squeeze and slight y-dimension squeeze\n",
    "        # This simulates more realistic perspective from floor where squares get thinner\n",
    "        # mostly horizontally and slightly vertically\n",
    "        pts = np.array([\n",
    "            [-half * x_squeeze, -half * y_squeeze],  # Top-left - squeezed in x and slightly in y\n",
    "            [half * x_squeeze, -half * y_squeeze],   # Top-right - squeezed in x and slightly in y\n",
    "            [half, half],                           # Bottom-right - normal\n",
    "            [-half, half]                           # Bottom-left - normal\n",
    "        ], dtype=np.float32)\n",
    "        \n",
    "        # Apply random horizontal shear to simulate different viewing angles\n",
    "        if random.random() < 0.7:\n",
    "            shear_factor = random.uniform(-0.3, 0.3)\n",
    "            shear_matrix = np.array([\n",
    "                [1, shear_factor, 0],\n",
    "                [0, 1, 0]\n",
    "            ], dtype=np.float32)\n",
    "            pts = np.dot(pts, shear_matrix[:,:2].T)\n",
    "        \n",
    "        pts += np.array([cx, cy])\n",
    "        pts = pts.astype(np.int32)\n",
    "        cv2.fillConvexPoly(img, pts, bgr)\n",
    "\n",
    "        x_min, y_min = np.min(pts, axis=0)\n",
    "        x_max, y_max = np.max(pts, axis=0)\n",
    "        x_center = ((x_min + x_max) / 2) / img_size\n",
    "        y_center = ((y_min + y_max) / 2) / img_size\n",
    "        w = (x_max - x_min) / img_size\n",
    "        h = (y_max - y_min) / img_size\n",
    "        label_lines.append(f\"{classid} {x_center:.6f} {y_center:.6f} {w:.6f} {h:.6f}\")\n",
    "\n",
    "    # Add distractor shapes\n",
    "    if distractor_shapes and random.random() < 0.5:\n",
    "        n = random.randint(1,3)\n",
    "        for _ in range(n):\n",
    "            img = random_distractor(img)\n",
    "\n",
    "    # Blurring & brightness\n",
    "    img = apply_random_blur(img)\n",
    "    img = apply_brightness(img)\n",
    "\n",
    "    fname = f\"synthetic_{i:05d}.jpg\"\n",
    "    img_path = os.path.join(img_dir, fname)\n",
    "    lbl_path = os.path.join(lbl_dir, fname.replace(\".jpg\", \".txt\"))\n",
    "    cv2.imwrite(img_path, img)\n",
    "    with open(lbl_path, \"w\") as f:\n",
    "        for line in label_lines:\n",
    "            f.write(line + \"\\n\")\n",
    "    all_image_paths.append(img_path)\n",
    "\n",
    "print(\"Dataset generated. Splitting into train/val...\")\n",
    "\n",
    "# --- Train/Val Split ---\n",
    "train_imgs, val_imgs = train_test_split(all_image_paths, test_size=0.15, random_state=42)\n",
    "for split, img_list in [(\"train\", train_imgs), (\"val\", val_imgs)]:\n",
    "    split_img_dir = os.path.join(output_dir, \"images\", split)\n",
    "    split_lbl_dir = os.path.join(output_dir, \"labels\", split)\n",
    "    os.makedirs(split_img_dir, exist_ok=True)\n",
    "    os.makedirs(split_lbl_dir, exist_ok=True)\n",
    "    for img_path in img_list:\n",
    "        base = os.path.basename(img_path)\n",
    "        lbl_path = os.path.join(lbl_dir, base.replace(\".jpg\",\".txt\"))\n",
    "        os.rename(img_path, os.path.join(split_img_dir, base))\n",
    "        os.rename(lbl_path, os.path.join(split_lbl_dir, base.replace(\".jpg\",\".txt\")))\n",
    "\n",
    "print(\"Done! Final structure is:\")\n",
    "print(f\"{output_dir}/images/train/  (images for training)\")\n",
    "print(f\"{output_dir}/images/val/    (images for validation)\")\n",
    "print(f\"{output_dir}/labels/train/  (labels for training)\")\n",
    "print(f\"{output_dir}/labels/val/    (labels for validation)\")\n",
    "\n",
    "# --- YAML for YOLOv8 ---\n",
    "yaml = f\"\"\"\n",
    "path: {os.path.abspath(output_dir)}\n",
    "train: images/train\n",
    "val: images/val\n",
    "nc: {len(colors)}\n",
    "names: {class_names}\n",
    "\"\"\"\n",
    "with open(os.path.join(output_dir, \"data.yaml\"), \"w\") as f:\n",
    "    f.write(yaml)\n",
    "\n",
    "print(\"data.yaml written!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8dffeee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file  \n",
      "View Ultralytics Settings with 'yolo settings' or at 'C:\\Users\\frjh19\\AppData\\Roaming\\Ultralytics\\settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "Training YOLOv8n model on synthetic squares dataset\n",
      "Using device: CPU\n",
      "Ultralytics 8.3.141  Python-3.10.4 torch-2.7.0+cpu CPU (13th Gen Intel Core(TM) i9-13900)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=synthetic_squares\\data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs\\detect\\train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to 'C:\\Users\\frjh19\\AppData\\Roaming\\Ultralytics\\Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 755k/755k [00:00<00:00, 11.7MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=6\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752482  ultralytics.nn.modules.head.Detect           [6, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,012,018 parameters, 3,012,002 gradients, 8.2 GFLOPs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 3.42.3 MB/s, size: 13.5 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\frjh19\\RoboticsProject\\Robotics\\synthetic_squares\\labels\\train... 1700 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1700/1700 [00:01<00:00, 1089.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\frjh19\\RoboticsProject\\Robotics\\synthetic_squares\\labels\\train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 6.83.3 MB/s, size: 23.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frjh19\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\frjh19\\RoboticsProject\\Robotics\\synthetic_squares\\labels\\val... 300 images, 0 backgrounds, 0 corrupt: 100%|██████████| 300/300 [00:00<00:00, 1113.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\frjh19\\RoboticsProject\\Robotics\\synthetic_squares\\labels\\val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frjh19\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50         0G     0.9239      2.745      1.149         10        224: 100%|██████████| 107/107 [00:24<00:00,  4.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.663      0.594      0.635       0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50         0G     0.7583      1.107      1.086         14        224: 100%|██████████| 107/107 [00:24<00:00,  4.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  5.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.876      0.844      0.912      0.768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50         0G     0.7274     0.9635      1.076         10        224: 100%|██████████| 107/107 [00:24<00:00,  4.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  5.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.893      0.881      0.942      0.804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/50         0G     0.7038     0.8929      1.059         14        224: 100%|██████████| 107/107 [00:23<00:00,  4.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  5.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.946      0.911      0.953      0.839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50         0G     0.6533     0.8191      1.037          8        224: 100%|██████████| 107/107 [00:24<00:00,  4.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  5.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.933      0.917      0.957      0.835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50         0G     0.6192     0.7535      1.008         18        224: 100%|██████████| 107/107 [00:24<00:00,  4.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  5.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.954      0.906      0.959      0.852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50         0G     0.5989     0.7419      1.009         14        224: 100%|██████████| 107/107 [00:24<00:00,  4.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.953      0.928      0.969      0.857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50         0G     0.5967     0.7041      1.005         17        224: 100%|██████████| 107/107 [00:24<00:00,  4.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.979      0.921      0.969      0.865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/107 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolov8\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_size\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimg_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpatience\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdevice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     30\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining complete!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel saved at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39msave_dir,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\ultralytics\\engine\\model.py:796\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    793\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m    795\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[1;32m--> 796\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[0;32m    798\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\ultralytics\\engine\\trainer.py:211\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    208\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 211\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\ultralytics\\engine\\trainer.py:399\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[1;34m(self, world_size)\u001b[0m\n\u001b[0;32m    394\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    395\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;241m*\u001b[39m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_items) \u001b[38;5;241m/\u001b[39m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_items\n\u001b[0;32m    396\u001b[0m     )\n\u001b[0;32m    398\u001b[0m \u001b[38;5;66;03m# Backward\u001b[39;00m\n\u001b[1;32m--> 399\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;66;03m# Optimize - https://pytorch.org/docs/master/notes/amp_examples.html\u001b[39;00m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ni \u001b[38;5;241m-\u001b[39m last_opt_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccumulate:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    647\u001b[0m     )\n\u001b[1;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\autograd\\__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 353\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\autograd\\graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    825\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    826\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training YOLOv8 on the synthetic dataset\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Configuration for YOLOv8 training\n",
    "config = {\n",
    "    \"model_size\": \"n\",        # n (nano), s (small), m (medium), l (large), x (xlarge)\n",
    "    \"epochs\": 50,             # Number of training epochs\n",
    "    \"batch_size\": 16,         # Batch size\n",
    "    \"img_size\": img_size,     # Use same image size as generated dataset\n",
    "    \"patience\": 10,           # Early stopping patience\n",
    "    \"device\": 0 if torch.cuda.is_available() else \"cpu\"  # Use GPU if available\n",
    "}\n",
    "\n",
    "print(f\"Training YOLOv8{config['model_size']} model on synthetic squares dataset\")\n",
    "print(f\"Using device: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")\n",
    "\n",
    "# Initialize pre-trained YOLOv8 model\n",
    "model = YOLO(f\"yolov8{config['model_size']}.pt\")\n",
    "\n",
    "# Train the model\n",
    "results = model.train(\n",
    "    data=os.path.join(output_dir, \"data.yaml\"),\n",
    "    epochs=config['epochs'],\n",
    "    imgsz=config['img_size'],\n",
    "    batch=config['batch_size'],\n",
    "    patience=config['patience'],\n",
    "    device=config['device'],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\nTraining complete!\")\n",
    "print(f\"Model saved at: {os.path.join(model.trainer.save_dir, 'weights', 'best.pt')}\")\n",
    "\n",
    "# Validate the model\n",
    "val_results = model.val()\n",
    "print(f\"Validation metrics: mAP@0.5={val_results.box.map50:.4f}, mAP@0.5:0.95={val_results.box.map:.4f}\")\n",
    "\n",
    "# Optional: Run inference on a sample image\n",
    "sample_img = os.path.join(output_dir, \"images\", \"val\", os.listdir(os.path.join(output_dir, \"images\", \"val\"))[0])\n",
    "results = model.predict(source=sample_img, save=True, conf=0.25)\n",
    "print(f\"Inference test complete. Results saved at: {model.predictor.save_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e03f16b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.141-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\program files\\python310\\lib\\site-packages (from ultralytics) (2.2.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\program files\\python310\\lib\\site-packages (from ultralytics) (3.10.1)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\frjh19\\appdata\\roaming\\python\\python310\\site-packages (from ultralytics) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\program files\\python310\\lib\\site-packages (from ultralytics) (11.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\program files\\python310\\lib\\site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\program files\\python310\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\program files\\python310\\lib\\site-packages (from ultralytics) (1.15.2)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\frjh19\\appdata\\roaming\\python\\python310\\site-packages (from ultralytics) (2.7.0)\n",
      "Collecting torchvision>=0.9.0 (from ultralytics)\n",
      "  Downloading torchvision-0.22.0-cp310-cp310-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\frjh19\\appdata\\roaming\\python\\python310\\site-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in c:\\program files\\python310\\lib\\site-packages (from ultralytics) (7.0.0)\n",
      "Collecting py-cpuinfo (from ultralytics)\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\program files\\python310\\lib\\site-packages (from ultralytics) (2.2.3)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\program files\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\program files\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\program files\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\program files\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\program files\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\program files\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\program files\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\program files\\python310\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\program files\\python310\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\program files\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\program files\\python310\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\program files\\python310\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\program files\\python310\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\program files\\python310\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
      "Requirement already satisfied: filelock in c:\\users\\frjh19\\appdata\\roaming\\python\\python310\\site-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\program files\\python310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.13.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\frjh19\\appdata\\roaming\\python\\python310\\site-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\frjh19\\appdata\\roaming\\python\\python310\\site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\program files\\python310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\frjh19\\appdata\\roaming\\python\\python310\\site-packages (from torch>=1.8.0->ultralytics) (2025.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\frjh19\\appdata\\roaming\\python\\python310\\site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\program files\\python310\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\program files\\python310\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Downloading ultralytics-8.3.141-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 23.7 MB/s eta 0:00:00\n",
      "Downloading torchvision-0.22.0-cp310-cp310-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 46.9 MB/s eta 0:00:00\n",
      "Downloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: py-cpuinfo, ultralytics-thop, torchvision, ultralytics\n",
      "\n",
      "   -------------------- ------------------- 2/4 [torchvision]\n",
      "   -------------------- ------------------- 2/4 [torchvision]\n",
      "   -------------------- ------------------- 2/4 [torchvision]\n",
      "   -------------------- ------------------- 2/4 [torchvision]\n",
      "   -------------------- ------------------- 2/4 [torchvision]\n",
      "   -------------------- ------------------- 2/4 [torchvision]\n",
      "   -------------------- ------------------- 2/4 [torchvision]\n",
      "   -------------------- ------------------- 2/4 [torchvision]\n",
      "   -------------------- ------------------- 2/4 [torchvision]\n",
      "   -------------------- ------------------- 2/4 [torchvision]\n",
      "   -------------------- ------------------- 2/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [ultralytics]\n",
      "   ------------------------------ --------- 3/4 [ultralytics]\n",
      "   ------------------------------ --------- 3/4 [ultralytics]\n",
      "   ------------------------------ --------- 3/4 [ultralytics]\n",
      "   ------------------------------ --------- 3/4 [ultralytics]\n",
      "   ------------------------------ --------- 3/4 [ultralytics]\n",
      "   ------------------------------ --------- 3/4 [ultralytics]\n",
      "   ------------------------------ --------- 3/4 [ultralytics]\n",
      "   ------------------------------ --------- 3/4 [ultralytics]\n",
      "   ---------------------------------------- 4/4 [ultralytics]\n",
      "\n",
      "Successfully installed py-cpuinfo-9.0.0 torchvision-0.22.0 ultralytics-8.3.141 ultralytics-thop-2.0.14\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
