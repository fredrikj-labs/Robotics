{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b09ffb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done. Annotated images saved to: C:\\Users\\fredr\\BTH\\Robotik Project\\Robotics\\YOLOv8-training\\jetbot_groundview_dataset\\val\\images\\eval_debug\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from glob import glob\n",
    "\n",
    "# ==== CONFIG ====\n",
    "MODEL_PATH = r\"C:\\Users\\fredr\\BTH\\Robotik Project\\Robotics\\YOLOv8-training\\runs\\train\\jetbot_groundview\\weights\\epoch60.pt\"\n",
    "IMAGE_DIR = r\"C:\\Users\\fredr\\BTH\\Robotik Project\\Robotics\\YOLOv8-training\\jetbot_groundview_dataset\\val\\images\"\n",
    "OUT_DIR = os.path.join(IMAGE_DIR, \"eval_debug\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# Model input size: this MUST match your model's training size!\n",
    "MODEL_IMG_SIZE = 512  # or 640, whatever you trained with!\n",
    "\n",
    "CLASS_NAMES = {0: \"jetbot1\", 1: \"jetbot2\", 2: \"jetbot3\", 3: \"red_box\"}\n",
    "\n",
    "def draw_box(img, box, label, color, thickness=2):\n",
    "    x1, y1, x2, y2 = map(int, box)\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), color, thickness)\n",
    "    cv2.putText(img, label, (x1, max(y1 - 10, 10)),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2, lineType=cv2.LINE_AA)\n",
    "\n",
    "def yolo_to_xyxy(cls_id, cx, cy, bw, bh, w, h):\n",
    "    # Converts YOLO txt normalized coords to pixel coords\n",
    "    x1 = int((cx - bw / 2) * w)\n",
    "    y1 = int((cy - bh / 2) * h)\n",
    "    x2 = int((cx + bw / 2) * w)\n",
    "    y2 = int((cy + bh / 2) * h)\n",
    "    return [x1, y1, x2, y2]\n",
    "\n",
    "def resize_and_pad(img, target_size):\n",
    "    h, w = img.shape[:2]\n",
    "    scale = min(target_size / w, target_size / h)\n",
    "    nw, nh = int(w * scale), int(h * scale)\n",
    "    img_resized = cv2.resize(img, (nw, nh))\n",
    "    top = (target_size - nh) // 2\n",
    "    bottom = target_size - nh - top\n",
    "    left = (target_size - nw) // 2\n",
    "    right = target_size - nw - left\n",
    "    img_padded = cv2.copyMakeBorder(img_resized, top, bottom, left, right, cv2.BORDER_CONSTANT, value=(114, 114, 114))\n",
    "    return img_padded, scale, left, top\n",
    "\n",
    "image_paths = sorted([\n",
    "    f for f in glob(os.path.join(IMAGE_DIR, \"*.png\"))\n",
    "    if \"debug\" not in os.path.basename(f)\n",
    "])[:100]\n",
    "\n",
    "model = YOLO(MODEL_PATH)\n",
    "\n",
    "for img_path in image_paths:\n",
    "    img = cv2.imread(img_path)\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    # 1. Preprocess for model: resize and pad to model size\n",
    "    img_input, scale, pad_x, pad_y = resize_and_pad(img, MODEL_IMG_SIZE)\n",
    "    \n",
    "    # 2. Run model on resized/padded input\n",
    "    results = model(img_input, imgsz=MODEL_IMG_SIZE, verbose=False)[0]\n",
    "\n",
    "    # 3. Map predicted boxes from model input size back to original image\n",
    "    for box, cls, conf in zip(results.boxes.xyxy.cpu(), results.boxes.cls.cpu(), results.boxes.conf.cpu()):\n",
    "        # Remove padding, then rescale\n",
    "        x1, y1, x2, y2 = box\n",
    "        # Remove padding\n",
    "        x1 = (x1 - pad_x) / scale\n",
    "        y1 = (y1 - pad_y) / scale\n",
    "        x2 = (x2 - pad_x) / scale\n",
    "        y2 = (y2 - pad_y) / scale\n",
    "        # Clip to image boundaries\n",
    "        x1 = int(max(0, min(x1, w - 1)))\n",
    "        y1 = int(max(0, min(y1, h - 1)))\n",
    "        x2 = int(max(0, min(x2, w - 1)))\n",
    "        y2 = int(max(0, min(y2, h - 1)))\n",
    "        label = f\"{CLASS_NAMES.get(int(cls), str(int(cls)))} {conf:.2f}\"\n",
    "        draw_box(img, (x1, y1, x2, y2), label, (0, 255, 0))\n",
    "\n",
    "    # 4. Draw GT boxes (BLUE) -- always correct\n",
    "    txt_path = img_path.replace(\".png\", \".txt\")\n",
    "    if os.path.exists(txt_path):\n",
    "        with open(txt_path, \"r\") as f:\n",
    "            for line in f:\n",
    "                if not line.strip():\n",
    "                    continue\n",
    "                cls_id, cx, cy, bw, bh = map(float, line.strip().split())\n",
    "                xyxy = yolo_to_xyxy(cls_id, cx, cy, bw, bh, w, h)\n",
    "                label = f\"GT {CLASS_NAMES.get(int(cls_id), str(int(cls_id)))}\"\n",
    "                draw_box(img, xyxy, label, (255, 0, 0))\n",
    "\n",
    "    # 5. Draw optional pose from JSON (ORANGE)\n",
    "    json_path = img_path.replace(\".png\", \".json\")\n",
    "    if os.path.exists(json_path):\n",
    "        with open(json_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "            pose_objects = data.get(\"pose_data\", []) if isinstance(data, dict) else data\n",
    "            for idx, obj in enumerate(pose_objects):\n",
    "                if \"robot_id\" in obj and \"relative_position\" in obj:\n",
    "                    rel_pos = obj[\"relative_position\"]\n",
    "                    yaw = obj.get(\"yaw\", 0)\n",
    "                    label = f\"{obj['robot_id']} pos=({rel_pos[0]:.2f}, {rel_pos[1]:.2f}) yaw={yaw:.2f}\"\n",
    "                    cv2.putText(img, label, (10, h - 10 - 20 * idx),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 200, 255), 1)\n",
    "\n",
    "    out_path = os.path.join(OUT_DIR, os.path.basename(img_path))\n",
    "    cv2.imwrite(out_path, img)\n",
    "\n",
    "print(f\"✅ Done. Annotated images saved to: {OUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69e0eb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Diagnostics done! Check C:\\temp\\debug_diags for all GT variants and predictions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from glob import glob\n",
    "\n",
    "# ==== CONFIG ====\n",
    "MODEL_PATH = r\"C:\\Users\\fredr\\BTH\\Robotik Project\\Robotics\\YOLOv8-training\\runs\\train\\jetbot_groundview\\weights\\epoch280.pt\"\n",
    "IMAGE_DIR = r\"C:\\temp\"\n",
    "OUT_DIR = os.path.join(IMAGE_DIR, \"debug_diags\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "MODEL_IMG_SIZE = 512  # Model input size\n",
    "CLASS_NAMES = {0: \"jetbot1\", 1: \"jetbot2\", 2: \"jetbot3\", 3: \"red_box\"}\n",
    "\n",
    "def draw_box(img, box, label, color, thickness=2):\n",
    "    x1, y1, x2, y2 = map(int, box)\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), color, thickness)\n",
    "    cv2.putText(img, label, (x1, max(y1 - 10, 10)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2, lineType=cv2.LINE_AA)\n",
    "\n",
    "def yolo_to_xyxy(cx, cy, bw, bh, w, h):\n",
    "    x1 = int((cx - bw / 2) * w)\n",
    "    y1 = int((cy - bh / 2) * h)\n",
    "    x2 = int((cx + bw / 2) * w)\n",
    "    y2 = int((cy + bh / 2) * h)\n",
    "    return [x1, y1, x2, y2]\n",
    "\n",
    "# Axis-swap/flip/scale diagnostic conversions\n",
    "def all_gt_variants(cls_id, cx, cy, bw, bh, w, h):\n",
    "    # Original\n",
    "    orig = yolo_to_xyxy(cx, cy, bw, bh, w, h)\n",
    "    # Swap x/y, bw/bh\n",
    "    swap = yolo_to_xyxy(cy, cx, bh, bw, w, h)\n",
    "    # Flip X (1-cx), keep others\n",
    "    flipx = yolo_to_xyxy(1-cx, cy, bw, bh, w, h)\n",
    "    # Flip Y (1-cy), keep others\n",
    "    flipy = yolo_to_xyxy(cx, 1-cy, bw, bh, w, h)\n",
    "    # Both flips\n",
    "    flipxy = yolo_to_xyxy(1-cx, 1-cy, bw, bh, w, h)\n",
    "    return {\n",
    "        \"GT_orig_BLUE\": (orig, (255, 0, 0)),\n",
    "        \"GT_swap_RED\": (swap, (0, 0, 255)),\n",
    "        \"GT_flipX_YELLOW\": (flipx, (0, 255, 255)),\n",
    "        \"GT_flipY_GREEN\": (flipy, (0, 255, 0)),\n",
    "        \"GT_flipXY_MAG\": (flipxy, (255, 0, 255))\n",
    "    }\n",
    "\n",
    "# Prepare test images\n",
    "image_paths = sorted([f for f in glob(os.path.join(IMAGE_DIR, \"*.png\")) if \"debug\" not in os.path.basename(f)])[:10]\n",
    "model = YOLO(MODEL_PATH)\n",
    "\n",
    "for img_path in image_paths:\n",
    "    img = cv2.imread(img_path)\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    # Model inference\n",
    "    img_input = cv2.resize(img, (MODEL_IMG_SIZE, MODEL_IMG_SIZE))\n",
    "    results = model(img_input, imgsz=MODEL_IMG_SIZE, verbose=False)[0]\n",
    "\n",
    "    # Map prediction boxes back to original image\n",
    "    scale = min(MODEL_IMG_SIZE/w, MODEL_IMG_SIZE/h)\n",
    "    nw, nh = int(w * scale), int(h * scale)\n",
    "    pad_x = (MODEL_IMG_SIZE - nw) // 2\n",
    "    pad_y = (MODEL_IMG_SIZE - nh) // 2\n",
    "\n",
    "    for box, cls, conf in zip(results.boxes.xyxy.cpu(), results.boxes.cls.cpu(), results.boxes.conf.cpu()):\n",
    "        x1, y1, x2, y2 = box\n",
    "        x1 = (x1 - pad_x) / scale\n",
    "        y1 = (y1 - pad_y) / scale\n",
    "        x2 = (x2 - pad_x) / scale\n",
    "        y2 = (y2 - pad_y) / scale\n",
    "        x1 = int(max(0, min(x1, w-1)))\n",
    "        y1 = int(max(0, min(y1, h-1)))\n",
    "        x2 = int(max(0, min(x2, w-1)))\n",
    "        y2 = int(max(0, min(y2, h-1)))\n",
    "        label = f\"{CLASS_NAMES.get(int(cls), str(int(cls)))} {conf:.2f}\"\n",
    "        draw_box(img, (x1, y1, x2, y2), label, (0, 255, 0))  # GREEN for model prediction\n",
    "\n",
    "    # Draw all GT variants\n",
    "    txt_path = img_path.replace(\".png\", \".txt\")\n",
    "    if os.path.exists(txt_path):\n",
    "        with open(txt_path, \"r\") as f:\n",
    "            for line in f:\n",
    "                if not line.strip(): continue\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) < 5: continue\n",
    "                cls_id, cx, cy, bw, bh = map(float, parts[:5])\n",
    "                gt_boxes = all_gt_variants(cls_id, cx, cy, bw, bh, w, h)\n",
    "                for key, (box, color) in gt_boxes.items():\n",
    "                    draw_box(img, box, key, color)\n",
    "\n",
    "    out_path = os.path.join(OUT_DIR, os.path.basename(img_path))\n",
    "    cv2.imwrite(out_path, img)\n",
    "\n",
    "print(f\"✅ Diagnostics done! Check {OUT_DIR} for all GT variants and predictions.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
