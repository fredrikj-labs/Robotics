{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31d9a313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal Robot Tracking System\n",
      "Python 3.6 Compatible\n",
      "--------------------------------------------------\n",
      "Python version: 3.9.18 (main, Sep 11 2023, 14:09:26) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'runs\\\\pose\\\\jetbot_orientation\\\\weights\\\\best.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 613\u001b[0m\n\u001b[0;32m    610\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ“ Python 3.6 detected - compatible!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    612\u001b[0m \u001b[38;5;66;03m# Run demo\u001b[39;00m\n\u001b[1;32m--> 613\u001b[0m \u001b[43mdemo_tracking\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 545\u001b[0m, in \u001b[0;36mdemo_tracking\u001b[1;34m()\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Demo tracking with webcam or video file\"\"\"\u001b[39;00m\n\u001b[0;32m    544\u001b[0m \u001b[38;5;66;03m# Initialize tracker\u001b[39;00m\n\u001b[1;32m--> 545\u001b[0m tracker \u001b[38;5;241m=\u001b[39m \u001b[43mTemporalRobotTracker\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mruns/pose/jetbot_orientation/weights/best.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_age\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    548\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_hits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[0;32m    549\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[38;5;66;03m# Open video\u001b[39;00m\n\u001b[0;32m    552\u001b[0m cap \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# or video file path\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 280\u001b[0m, in \u001b[0;36mTemporalRobotTracker.__init__\u001b[1;34m(self, model_path, max_age, min_hits)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[1;32m--> 280\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mYOLO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install ultralytics: pip install ultralytics==8.0.0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\fredr\\anaconda3\\lib\\site-packages\\ultralytics\\models\\yolo\\model.py:53\u001b[0m, in \u001b[0;36mYOLO.__init__\u001b[1;34m(self, model, task, verbose)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m \u001b[38;5;241m=\u001b[39m new_instance\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;66;03m# Continue with default YOLO initialization\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRTDETR\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmodel[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39m_get_name():  \u001b[38;5;66;03m# if RTDETR head\u001b[39;00m\n\u001b[0;32m     55\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RTDETR\n",
      "File \u001b[1;32mc:\\Users\\fredr\\anaconda3\\lib\\site-packages\\ultralytics\\engine\\model.py:151\u001b[0m, in \u001b[0;36mModel.__init__\u001b[1;34m(self, model, task, verbose)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(model, task\u001b[38;5;241m=\u001b[39mtask, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 151\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# Delete super().training for accessing self.model.training\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining\n",
      "File \u001b[1;32mc:\\Users\\fredr\\anaconda3\\lib\\site-packages\\ultralytics\\engine\\model.py:295\u001b[0m, in \u001b[0;36mModel._load\u001b[1;34m(self, weights, task)\u001b[0m\n\u001b[0;32m    292\u001b[0m weights \u001b[38;5;241m=\u001b[39m checks\u001b[38;5;241m.\u001b[39mcheck_model_file_from_stem(weights)  \u001b[38;5;66;03m# add suffix, i.e. yolo11n -> yolo11n.pt\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(weights)\u001b[38;5;241m.\u001b[39mrpartition(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 295\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;241m=\u001b[39m \u001b[43mattempt_load_one_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    297\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset_ckpt_args(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\fredr\\anaconda3\\lib\\site-packages\\ultralytics\\nn\\tasks.py:1334\u001b[0m, in \u001b[0;36mattempt_load_one_weight\u001b[1;34m(weight, device, inplace, fuse)\u001b[0m\n\u001b[0;32m   1321\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mattempt_load_one_weight\u001b[39m(weight, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fuse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1323\u001b[0m \u001b[38;5;124;03m    Load a single model weights.\u001b[39;00m\n\u001b[0;32m   1324\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1332\u001b[0m \u001b[38;5;124;03m        (tuple): Tuple containing the model and checkpoint.\u001b[39;00m\n\u001b[0;32m   1333\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1334\u001b[0m     ckpt, weight \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_safe_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# load ckpt\u001b[39;00m\n\u001b[0;32m   1335\u001b[0m     args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mDEFAULT_CFG_DICT, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_args\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))}  \u001b[38;5;66;03m# combine model and default args, preferring model args\u001b[39;00m\n\u001b[0;32m   1336\u001b[0m     model \u001b[38;5;241m=\u001b[39m (ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mema\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m ckpt[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# FP32 model\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fredr\\anaconda3\\lib\\site-packages\\ultralytics\\nn\\tasks.py:1239\u001b[0m, in \u001b[0;36mtorch_safe_load\u001b[1;34m(weight, safe_only)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                 ckpt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(f, pickle_module\u001b[38;5;241m=\u001b[39msafe_pickle)\n\u001b[0;32m   1238\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1239\u001b[0m             ckpt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1241\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# e.name is missing module name\u001b[39;00m\n\u001b[0;32m   1242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\fredr\\anaconda3\\lib\\site-packages\\ultralytics\\utils\\patches.py:116\u001b[0m, in \u001b[0;36mtorch_load\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TORCH_1_13 \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights_only\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[0;32m    114\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights_only\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _torch_load(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\fredr\\anaconda3\\lib\\site-packages\\torch\\serialization.py:1319\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1317\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1319\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1321\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1322\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1323\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1324\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32mc:\\Users\\fredr\\anaconda3\\lib\\site-packages\\torch\\serialization.py:659\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    658\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 659\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    661\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32mc:\\Users\\fredr\\anaconda3\\lib\\site-packages\\torch\\serialization.py:640\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 640\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'runs\\\\pose\\\\jetbot_orientation\\\\weights\\\\best.pt'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Real-time Jetbot tracking with temporal smoothing and improved color identification\n",
    "Compatible with Python 3.6 (Jetbot environment)\n",
    "\"\"\"\n",
    "\n",
    "# Python 3.6 compatible imports\n",
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque, defaultdict\n",
    "import time\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# For Python 3.6 compatibility\n",
    "try:\n",
    "    from typing import Dict, List, Tuple, Optional, Any\n",
    "except ImportError:\n",
    "    # Python 3.6 might have issues with some typing imports\n",
    "    pass\n",
    "\n",
    "\n",
    "class KalmanTracker:\n",
    "    \"\"\"\n",
    "    Kalman filter for smooth tracking of robot positions and orientations\n",
    "    Handles temporal consistency across frames\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dt=1.0/30.0):\n",
    "        \"\"\"Initialize Kalman filter for 2D position + orientation tracking\"\"\"\n",
    "        self.dt = dt\n",
    "        \n",
    "        # State: [x, y, vx, vy, theta, omega]\n",
    "        self.kf = cv2.KalmanFilter(6, 3)\n",
    "        \n",
    "        # State transition matrix\n",
    "        self.kf.transitionMatrix = np.array([\n",
    "            [1, 0, dt, 0,  0, 0],\n",
    "            [0, 1, 0,  dt, 0, 0],\n",
    "            [0, 0, 1,  0,  0, 0],\n",
    "            [0, 0, 0,  1,  0, 0],\n",
    "            [0, 0, 0,  0,  1, dt],\n",
    "            [0, 0, 0,  0,  0, 1]\n",
    "        ], dtype=np.float32)\n",
    "        \n",
    "        # Measurement matrix\n",
    "        self.kf.measurementMatrix = np.array([\n",
    "            [1, 0, 0, 0, 0, 0],\n",
    "            [0, 1, 0, 0, 0, 0],\n",
    "            [0, 0, 0, 0, 1, 0]\n",
    "        ], dtype=np.float32)\n",
    "        \n",
    "        # Process noise\n",
    "        self.kf.processNoiseCov = np.eye(6, dtype=np.float32) * 0.03\n",
    "        \n",
    "        # Measurement noise\n",
    "        self.kf.measurementNoiseCov = np.eye(3, dtype=np.float32) * 0.1\n",
    "        \n",
    "        # Error covariance\n",
    "        self.kf.errorCovPost = np.eye(6, dtype=np.float32)\n",
    "        \n",
    "        # Initial state\n",
    "        self.initialized = False\n",
    "        \n",
    "    def init_state(self, x, y, theta):\n",
    "        \"\"\"Initialize tracker with first measurement\"\"\"\n",
    "        self.kf.statePre = np.array([x, y, 0, 0, theta, 0], dtype=np.float32)\n",
    "        self.kf.statePost = self.kf.statePre.copy()\n",
    "        self.initialized = True\n",
    "        \n",
    "    def predict(self):\n",
    "        \"\"\"Predict next state\"\"\"\n",
    "        if self.initialized:\n",
    "            return self.kf.predict()\n",
    "        return None\n",
    "        \n",
    "    def update(self, x, y, theta):\n",
    "        \"\"\"Update with measurement\"\"\"\n",
    "        if not self.initialized:\n",
    "            self.init_state(x, y, theta)\n",
    "            return self.kf.statePost\n",
    "        \n",
    "        measurement = np.array([x, y, theta], dtype=np.float32)\n",
    "        self.kf.correct(measurement)\n",
    "        return self.kf.statePost\n",
    "\n",
    "\n",
    "class ColorIdentifier:\n",
    "    \"\"\"\n",
    "    Robust color identification for robot markers using HSV space and ML\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Define HSV ranges for colors (tuned for common lighting conditions)\n",
    "        # Format: (lower_hsv, upper_hsv, color_name)\n",
    "        self.color_ranges = [\n",
    "            # Red (wraps around 0)\n",
    "            (np.array([0, 70, 50]), np.array([10, 255, 255]), \"red\"),\n",
    "            (np.array([170, 70, 50]), np.array([180, 255, 255]), \"red\"),\n",
    "            \n",
    "            # Orange (distinct from red and yellow)\n",
    "            (np.array([11, 100, 100]), np.array([20, 255, 255]), \"orange\"),\n",
    "            \n",
    "            # Yellow (distinct from orange)\n",
    "            (np.array([21, 100, 100]), np.array([30, 255, 255]), \"yellow\"),\n",
    "            \n",
    "            # Green\n",
    "            (np.array([35, 40, 40]), np.array([85, 255, 255]), \"green\"),\n",
    "            \n",
    "            # Blue (distinct from light blue)\n",
    "            (np.array([100, 100, 50]), np.array([120, 255, 255]), \"blue\"),\n",
    "            \n",
    "            # Light Blue / Cyan\n",
    "            (np.array([86, 50, 50]), np.array([99, 255, 255]), \"light_blue\"),\n",
    "            \n",
    "            # Purple / Violet\n",
    "            (np.array([121, 40, 40]), np.array([140, 255, 255]), \"purple\"),\n",
    "            \n",
    "            # Brown (in HSV, similar to dark orange)\n",
    "            (np.array([10, 50, 20]), np.array([20, 255, 100]), \"brown\"),\n",
    "            \n",
    "            # Pink\n",
    "            (np.array([140, 30, 100]), np.array([170, 100, 255]), \"pink\"),\n",
    "            \n",
    "            # White\n",
    "            (np.array([0, 0, 200]), np.array([180, 30, 255]), \"white\"),\n",
    "            \n",
    "            # Black/Gray\n",
    "            (np.array([0, 0, 0]), np.array([180, 30, 100]), \"black\"),\n",
    "        ]\n",
    "        \n",
    "        # Color confusion matrix for post-processing\n",
    "        self.confusion_pairs = {\n",
    "            (\"orange\", \"brown\"): self._distinguish_orange_brown,\n",
    "            (\"yellow\", \"orange\"): self._distinguish_yellow_orange,\n",
    "            (\"blue\", \"light_blue\"): self._distinguish_blue_lightblue,\n",
    "        }\n",
    "        \n",
    "    def identify_color(self, image_region):\n",
    "        \"\"\"\n",
    "        Identify color of a robot marker region\n",
    "        Returns (color_name, confidence)\n",
    "        \"\"\"\n",
    "        if image_region.size == 0:\n",
    "            return \"unknown\", 0.0\n",
    "            \n",
    "        # Convert to HSV\n",
    "        hsv = cv2.cvtColor(image_region, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        # Find dominant color\n",
    "        color_scores = {}\n",
    "        \n",
    "        for lower, upper, color_name in self.color_ranges:\n",
    "            # Create mask\n",
    "            if color_name == \"red\":\n",
    "                # Special handling for red (wraps around)\n",
    "                mask1 = cv2.inRange(hsv, self.color_ranges[0][0], self.color_ranges[0][1])\n",
    "                mask2 = cv2.inRange(hsv, self.color_ranges[1][0], self.color_ranges[1][1])\n",
    "                mask = cv2.bitwise_or(mask1, mask2)\n",
    "            else:\n",
    "                mask = cv2.inRange(hsv, lower, upper)\n",
    "            \n",
    "            # Calculate percentage of pixels matching this color\n",
    "            score = cv2.countNonZero(mask) / (hsv.shape[0] * hsv.shape[1])\n",
    "            \n",
    "            if color_name in color_scores:\n",
    "                color_scores[color_name] = max(color_scores[color_name], score)\n",
    "            else:\n",
    "                color_scores[color_name] = score\n",
    "        \n",
    "        # Get top 2 colors\n",
    "        sorted_colors = sorted(color_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        if len(sorted_colors) == 0:\n",
    "            return \"unknown\", 0.0\n",
    "            \n",
    "        best_color = sorted_colors[0][0]\n",
    "        best_score = sorted_colors[0][1]\n",
    "        \n",
    "        # Check for confusion pairs\n",
    "        if len(sorted_colors) > 1:\n",
    "            second_color = sorted_colors[1][0]\n",
    "            \n",
    "            # Check if these are commonly confused colors\n",
    "            pair = tuple(sorted([best_color, second_color]))\n",
    "            if pair in self.confusion_pairs:\n",
    "                # Use specialized distinguisher\n",
    "                best_color = self.confusion_pairs[pair](image_region, best_color, second_color)\n",
    "        \n",
    "        # Additional features for difficult cases\n",
    "        if best_score < 0.3:  # Low confidence\n",
    "            best_color = self._analyze_color_features(image_region)\n",
    "            \n",
    "        return best_color, best_score\n",
    "    \n",
    "    def _distinguish_orange_brown(self, img, color1, color2):\n",
    "        \"\"\"Distinguish between orange and brown using brightness\"\"\"\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        brightness = np.mean(gray)\n",
    "        \n",
    "        # Orange is typically brighter than brown\n",
    "        if brightness > 100:\n",
    "            return \"orange\"\n",
    "        else:\n",
    "            return \"brown\"\n",
    "    \n",
    "    def _distinguish_yellow_orange(self, img, color1, color2):\n",
    "        \"\"\"Distinguish between yellow and orange using hue histogram\"\"\"\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        hue = hsv[:, :, 0]\n",
    "        \n",
    "        # Yellow has higher hue values than orange\n",
    "        mean_hue = np.mean(hue)\n",
    "        if mean_hue > 25:\n",
    "            return \"yellow\"\n",
    "        else:\n",
    "            return \"orange\"\n",
    "    \n",
    "    def _distinguish_blue_lightblue(self, img, color1, color2):\n",
    "        \"\"\"Distinguish between blue and light blue using saturation\"\"\"\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        saturation = hsv[:, :, 1]\n",
    "        \n",
    "        # Light blue typically has lower saturation\n",
    "        mean_sat = np.mean(saturation)\n",
    "        if mean_sat < 100:\n",
    "            return \"light_blue\"\n",
    "        else:\n",
    "            return \"blue\"\n",
    "    \n",
    "    def _analyze_color_features(self, img):\n",
    "        \"\"\"Analyze color using multiple features for difficult cases\"\"\"\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        # Calculate color statistics\n",
    "        mean_hue = np.mean(hsv[:, :, 0])\n",
    "        mean_sat = np.mean(hsv[:, :, 1])\n",
    "        mean_val = np.mean(hsv[:, :, 2])\n",
    "        \n",
    "        # Rule-based classification for edge cases\n",
    "        if mean_sat < 30:\n",
    "            if mean_val > 200:\n",
    "                return \"white\"\n",
    "            elif mean_val < 50:\n",
    "                return \"black\"\n",
    "            else:\n",
    "                return \"gray\"\n",
    "        \n",
    "        # Default to hue-based classification\n",
    "        if mean_hue < 15 or mean_hue > 170:\n",
    "            return \"red\"\n",
    "        elif mean_hue < 25:\n",
    "            return \"orange\"\n",
    "        elif mean_hue < 35:\n",
    "            return \"yellow\"\n",
    "        elif mean_hue < 85:\n",
    "            return \"green\"\n",
    "        elif mean_hue < 125:\n",
    "            return \"blue\"\n",
    "        else:\n",
    "            return \"purple\"\n",
    "\n",
    "\n",
    "class TemporalRobotTracker:\n",
    "    \"\"\"\n",
    "    Main tracker combining YOLO detection with temporal smoothing and color ID\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_path, max_age=5, min_hits=3):\n",
    "        \"\"\"\n",
    "        Initialize tracker\n",
    "        \n",
    "        Args:\n",
    "            model_path: Path to trained YOLOv8-pose model\n",
    "            max_age: Maximum frames to keep track without detection\n",
    "            min_hits: Minimum detections before track is confirmed\n",
    "        \"\"\"\n",
    "        # Python 3.6 compatible model loading\n",
    "        try:\n",
    "            from ultralytics import YOLO\n",
    "            self.model = YOLO(model_path)\n",
    "        except ImportError:\n",
    "            raise ImportError(\"Please install ultralytics: pip install ultralytics==8.0.0\")\n",
    "        \n",
    "        self.max_age = max_age\n",
    "        self.min_hits = min_hits\n",
    "        \n",
    "        # Track storage\n",
    "        self.tracks = {}  # track_id -> track_info\n",
    "        self.next_id = 0\n",
    "        \n",
    "        # Kalman trackers\n",
    "        self.kalman_trackers = {}  # track_id -> KalmanTracker\n",
    "        \n",
    "        # Color identifier\n",
    "        self.color_identifier = ColorIdentifier()\n",
    "        \n",
    "        # History for temporal consistency\n",
    "        self.detection_history = deque(maxlen=10)\n",
    "        \n",
    "    def update(self, frame):\n",
    "        \"\"\"\n",
    "        Update tracks with new frame\n",
    "        \n",
    "        Returns:\n",
    "            List of tracks: [(track_id, bbox, orientation, color, confidence)]\n",
    "        \"\"\"\n",
    "        # Run YOLO detection\n",
    "        results = self.model(frame, conf=0.25, verbose=False)\n",
    "        \n",
    "        current_detections = []\n",
    "        \n",
    "        for r in results:\n",
    "            if r.boxes is not None:\n",
    "                boxes = r.boxes.xyxy.cpu().numpy()\n",
    "                classes = r.boxes.cls.cpu().numpy().astype(int)\n",
    "                confs = r.boxes.conf.cpu().numpy()\n",
    "                \n",
    "                # Get keypoints for orientation\n",
    "                keypoints = None\n",
    "                if hasattr(r, 'keypoints') and r.keypoints is not None:\n",
    "                    keypoints = r.keypoints.xy.cpu().numpy()\n",
    "                \n",
    "                for i, (box, cls, conf) in enumerate(zip(boxes, classes, confs)):\n",
    "                    if cls == 0:  # Robot class\n",
    "                        x1, y1, x2, y2 = box\n",
    "                        cx = (x1 + x2) / 2\n",
    "                        cy = (y1 + y2) / 2\n",
    "                        \n",
    "                        # Calculate orientation from keypoint\n",
    "                        orientation = 0.0\n",
    "                        if keypoints is not None and i < len(keypoints):\n",
    "                            kp = keypoints[i]\n",
    "                            if len(kp) > 0 and kp[0][0] > 0:\n",
    "                                orientation = np.arctan2(kp[0][1] - cy, kp[0][0] - cx)\n",
    "                        \n",
    "                        # Extract color from marker region\n",
    "                        color = self._identify_robot_color(frame, box)\n",
    "                        \n",
    "                        current_detections.append({\n",
    "                            'bbox': box,\n",
    "                            'center': (cx, cy),\n",
    "                            'orientation': orientation,\n",
    "                            'color': color,\n",
    "                            'confidence': conf\n",
    "                        })\n",
    "        \n",
    "        # Update tracks using Hungarian algorithm\n",
    "        updated_tracks = self._update_tracks(current_detections)\n",
    "        \n",
    "        # Add to history\n",
    "        self.detection_history.append(current_detections)\n",
    "        \n",
    "        return updated_tracks\n",
    "    \n",
    "    def _identify_robot_color(self, frame, bbox):\n",
    "        \"\"\"Extract and identify color from robot marker region\"\"\"\n",
    "        x1, y1, x2, y2 = bbox.astype(int)\n",
    "        \n",
    "        # Extract region above robot center (where marker is)\n",
    "        height = y2 - y1\n",
    "        marker_region = frame[\n",
    "            max(0, y1):max(0, y1 + int(height * 0.3)),\n",
    "            x1:x2\n",
    "        ]\n",
    "        \n",
    "        if marker_region.size > 0:\n",
    "            color, confidence = self.color_identifier.identify_color(marker_region)\n",
    "            return color\n",
    "        \n",
    "        return \"unknown\"\n",
    "    \n",
    "    def _update_tracks(self, detections):\n",
    "        \"\"\"Update existing tracks and create new ones\"\"\"\n",
    "        # Predict current positions\n",
    "        for track_id, kalman in self.kalman_trackers.items():\n",
    "            kalman.predict()\n",
    "        \n",
    "        # Associate detections to tracks\n",
    "        if len(self.tracks) == 0:\n",
    "            # No existing tracks, create new ones\n",
    "            for det in detections:\n",
    "                self._create_track(det)\n",
    "        else:\n",
    "            # Match detections to existing tracks\n",
    "            matched, unmatched_dets, unmatched_tracks = self._associate_detections(detections)\n",
    "            \n",
    "            # Update matched tracks\n",
    "            for det_idx, track_id in matched:\n",
    "                self._update_track(track_id, detections[det_idx])\n",
    "            \n",
    "            # Create new tracks for unmatched detections\n",
    "            for det_idx in unmatched_dets:\n",
    "                self._create_track(detections[det_idx])\n",
    "            \n",
    "            # Mark unmatched tracks as missed\n",
    "            for track_id in unmatched_tracks:\n",
    "                self.tracks[track_id]['age'] += 1\n",
    "                \n",
    "                # Remove old tracks\n",
    "                if self.tracks[track_id]['age'] > self.max_age:\n",
    "                    del self.tracks[track_id]\n",
    "                    del self.kalman_trackers[track_id]\n",
    "        \n",
    "        # Return confirmed tracks\n",
    "        confirmed_tracks = []\n",
    "        for track_id, track in self.tracks.items():\n",
    "            if track['hits'] >= self.min_hits:\n",
    "                # Get smoothed position from Kalman filter\n",
    "                if track_id in self.kalman_trackers:\n",
    "                    state = self.kalman_trackers[track_id].kf.statePost\n",
    "                    smoothed_x = state[0]\n",
    "                    smoothed_y = state[1]\n",
    "                    smoothed_theta = state[4]\n",
    "                    \n",
    "                    # Update bbox center with smoothed position\n",
    "                    bbox = track['bbox'].copy()\n",
    "                    width = bbox[2] - bbox[0]\n",
    "                    height = bbox[3] - bbox[1]\n",
    "                    bbox[0] = smoothed_x - width/2\n",
    "                    bbox[1] = smoothed_y - height/2\n",
    "                    bbox[2] = smoothed_x + width/2\n",
    "                    bbox[3] = smoothed_y + height/2\n",
    "                    \n",
    "                    confirmed_tracks.append({\n",
    "                        'track_id': track_id,\n",
    "                        'bbox': bbox,\n",
    "                        'orientation': smoothed_theta,\n",
    "                        'color': track['color'],\n",
    "                        'confidence': track['confidence']\n",
    "                    })\n",
    "        \n",
    "        return confirmed_tracks\n",
    "    \n",
    "    def _create_track(self, detection):\n",
    "        \"\"\"Create new track\"\"\"\n",
    "        track_id = self.next_id\n",
    "        self.next_id += 1\n",
    "        \n",
    "        self.tracks[track_id] = {\n",
    "            'bbox': detection['bbox'],\n",
    "            'center': detection['center'],\n",
    "            'orientation': detection['orientation'],\n",
    "            'color': detection['color'],\n",
    "            'confidence': detection['confidence'],\n",
    "            'hits': 1,\n",
    "            'age': 0\n",
    "        }\n",
    "        \n",
    "        # Create Kalman tracker\n",
    "        kalman = KalmanTracker()\n",
    "        kalman.init_state(\n",
    "            detection['center'][0],\n",
    "            detection['center'][1],\n",
    "            detection['orientation']\n",
    "        )\n",
    "        self.kalman_trackers[track_id] = kalman\n",
    "    \n",
    "    def _update_track(self, track_id, detection):\n",
    "        \"\"\"Update existing track with new detection\"\"\"\n",
    "        track = self.tracks[track_id]\n",
    "        \n",
    "        # Update track info\n",
    "        track['bbox'] = detection['bbox']\n",
    "        track['center'] = detection['center']\n",
    "        track['orientation'] = detection['orientation']\n",
    "        track['confidence'] = detection['confidence']\n",
    "        track['hits'] += 1\n",
    "        track['age'] = 0\n",
    "        \n",
    "        # Update color with temporal consistency\n",
    "        if detection['color'] != \"unknown\":\n",
    "            track['color'] = detection['color']\n",
    "        \n",
    "        # Update Kalman filter\n",
    "        if track_id in self.kalman_trackers:\n",
    "            self.kalman_trackers[track_id].update(\n",
    "                detection['center'][0],\n",
    "                detection['center'][1],\n",
    "                detection['orientation']\n",
    "            )\n",
    "    \n",
    "    def _associate_detections(self, detections):\n",
    "        \"\"\"Associate detections to tracks using IoU and color similarity\"\"\"\n",
    "        if len(detections) == 0:\n",
    "            return [], [], list(self.tracks.keys())\n",
    "        \n",
    "        if len(self.tracks) == 0:\n",
    "            return [], list(range(len(detections))), []\n",
    "        \n",
    "        # Build cost matrix\n",
    "        track_ids = list(self.tracks.keys())\n",
    "        cost_matrix = np.zeros((len(detections), len(track_ids)))\n",
    "        \n",
    "        for d, det in enumerate(detections):\n",
    "            for t, track_id in enumerate(track_ids):\n",
    "                track = self.tracks[track_id]\n",
    "                \n",
    "                # IoU cost\n",
    "                iou = self._compute_iou(det['bbox'], track['bbox'])\n",
    "                \n",
    "                # Color similarity\n",
    "                color_sim = 1.0 if det['color'] == track['color'] else 0.5\n",
    "                \n",
    "                # Combined cost (lower is better)\n",
    "                cost_matrix[d, t] = 1 - (iou * color_sim)\n",
    "        \n",
    "        # Hungarian algorithm\n",
    "        from scipy.optimize import linear_sum_assignment\n",
    "        det_indices, track_indices = linear_sum_assignment(cost_matrix)\n",
    "        \n",
    "        # Filter matches by threshold\n",
    "        matched = []\n",
    "        for d, t in zip(det_indices, track_indices):\n",
    "            if cost_matrix[d, t] < 0.7:  # Threshold\n",
    "                matched.append((d, track_ids[t]))\n",
    "        \n",
    "        # Find unmatched\n",
    "        unmatched_dets = [d for d in range(len(detections)) \n",
    "                         if d not in [m[0] for m in matched]]\n",
    "        unmatched_tracks = [track_ids[t] for t in range(len(track_ids))\n",
    "                           if track_ids[t] not in [m[1] for m in matched]]\n",
    "        \n",
    "        return matched, unmatched_dets, unmatched_tracks\n",
    "    \n",
    "    def _compute_iou(self, box1, box2):\n",
    "        \"\"\"Compute IoU between two boxes\"\"\"\n",
    "        x1 = max(box1[0], box2[0])\n",
    "        y1 = max(box1[1], box2[1])\n",
    "        x2 = min(box1[2], box2[2])\n",
    "        y2 = min(box1[3], box2[3])\n",
    "        \n",
    "        intersection = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "        area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "        area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "        union = area1 + area2 - intersection\n",
    "        \n",
    "        return intersection / union if union > 0 else 0\n",
    "\n",
    "\n",
    "# Python 3.6 compatible demo\n",
    "def demo_tracking():\n",
    "    \"\"\"Demo tracking with webcam or video file\"\"\"\n",
    "    \n",
    "    # Initialize tracker\n",
    "    tracker = TemporalRobotTracker(\n",
    "        model_path=\"runs/pose/jetbot_orientation/weights/best.pt\",\n",
    "        max_age=5,\n",
    "        min_hits=2\n",
    "    )\n",
    "    \n",
    "    # Open video\n",
    "    cap = cv2.VideoCapture(0)  # or video file path\n",
    "    \n",
    "    # Color palette for tracks\n",
    "    colors = [\n",
    "        (255, 0, 0), (0, 255, 0), (0, 0, 255),\n",
    "        (255, 255, 0), (255, 0, 255), (0, 255, 255),\n",
    "        (128, 0, 0), (0, 128, 0), (0, 0, 128)\n",
    "    ]\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Update tracker\n",
    "        tracks = tracker.update(frame)\n",
    "        \n",
    "        # Visualize\n",
    "        for track in tracks:\n",
    "            track_id = track['track_id']\n",
    "            bbox = track['bbox'].astype(int)\n",
    "            orientation = track['orientation']\n",
    "            robot_color = track['color']\n",
    "            \n",
    "            # Draw bbox\n",
    "            color = colors[track_id % len(colors)]\n",
    "            cv2.rectangle(frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), color, 2)\n",
    "            \n",
    "            # Draw orientation\n",
    "            cx = int((bbox[0] + bbox[2]) / 2)\n",
    "            cy = int((bbox[1] + bbox[3]) / 2)\n",
    "            ex = int(cx + 50 * np.cos(orientation))\n",
    "            ey = int(cy + 50 * np.sin(orientation))\n",
    "            cv2.arrowedLine(frame, (cx, cy), (ex, ey), (0, 255, 255), 3)\n",
    "            \n",
    "            # Draw ID and color\n",
    "            label = \"ID:{} {}\".format(track_id, robot_color)\n",
    "            cv2.putText(frame, label, (bbox[0], bbox[1]-5),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "        \n",
    "        cv2.imshow(\"Tracking\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Temporal Robot Tracking System\")\n",
    "    print(\"Python 3.6 Compatible\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Check Python version\n",
    "    import sys\n",
    "    print(\"Python version: {}\".format(sys.version))\n",
    "    \n",
    "    if sys.version_info[0] == 3 and sys.version_info[1] == 6:\n",
    "        print(\"âœ“ Python 3.6 detected - compatible!\")\n",
    "    \n",
    "    # Run demo\n",
    "    demo_tracking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07987745",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
