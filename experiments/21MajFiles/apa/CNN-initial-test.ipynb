{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc39e4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:07<00:00, 270.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset generated. Splitting into train/val...\n",
      "Done! Final structure is:\n",
      "synthetic_squares/images/train/  (images for training)\n",
      "synthetic_squares/images/val/    (images for validation)\n",
      "synthetic_squares/labels/train/  (labels for training)\n",
      "synthetic_squares/labels/val/    (labels for validation)\n",
      "data.yaml written!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image, ImageEnhance\n",
    "\n",
    "# CONFIG\n",
    "output_dir = \"synthetic_squares\"\n",
    "img_dir = os.path.join(output_dir, \"images\")\n",
    "lbl_dir = os.path.join(output_dir, \"labels\")\n",
    "os.makedirs(img_dir, exist_ok=True)\n",
    "os.makedirs(lbl_dir, exist_ok=True)\n",
    "\n",
    "img_size = 224\n",
    "total_images = 2000           # Total images (across train/val)\n",
    "min_squares = 1\n",
    "max_squares = 3               # Up to N colored squares per image\n",
    "distractor_shapes = True      # Add circles/triangles for difficulty\n",
    "blur_prob = 0.3\n",
    "brightness_jitter = 0.25\n",
    "real_bg_prob = 0.4            # Use real backgrounds X% of the time\n",
    "\n",
    "colors = {\n",
    "    \"blue\":   ((255,  30,  30), 0),\n",
    "    \"red\":    ((30,  30, 255), 1),\n",
    "    \"orange\": ((0, 165, 255), 2),\n",
    "    \"yellow\": ((0, 255, 255), 3),\n",
    "    \"purple\": ((200,  80, 200), 4),\n",
    "    \"brown\":  ((19,  69, 139), 5)\n",
    "}\n",
    "class_names = list(colors.keys())\n",
    "\n",
    "backgrounds = [\n",
    "    (240,240,240), (255,255,255), (200,200,200), (160,160,160),\n",
    "    (220,200,170), (230,230,210)\n",
    "]\n",
    "\n",
    "# Optional: supply your own real image backgrounds (landscape, desk, etc)\n",
    "real_bg_folder = \"real_backgrounds\"\n",
    "real_bg_files = glob.glob(os.path.join(real_bg_folder, \"*.jpg\"))\n",
    "\n",
    "def make_background():\n",
    "    if random.random() < real_bg_prob and real_bg_files:\n",
    "        bg = Image.open(random.choice(real_bg_files)).resize((img_size, img_size)).convert(\"RGB\")\n",
    "        bg = np.array(bg)\n",
    "    else:\n",
    "        bg = np.full((img_size, img_size, 3), random.choice(backgrounds), dtype=np.uint8)\n",
    "        # Add noise\n",
    "        if random.random() < 0.4:\n",
    "            noise = np.random.normal(0, 10, (img_size, img_size, 3))\n",
    "            bg = np.clip(bg + noise, 0, 255).astype(np.uint8)\n",
    "    return bg\n",
    "\n",
    "def random_square_params():\n",
    "    cx = random.randint(int(0.2*img_size), int(0.8*img_size))\n",
    "    cy = random.randint(int(0.2*img_size), int(0.8*img_size))\n",
    "    size = random.randint(int(0.18*img_size), int(0.5*img_size))\n",
    "    \n",
    "    # MODIFIED: Apply perspective transform with primary x-direction squeeze\n",
    "    # and slight y-direction squeeze for more realistic perspective\n",
    "    x_squeeze = random.uniform(0.4, 1.0)  # Primary squeeze in x direction (1.0 = no squeeze)\n",
    "    y_squeeze = random.uniform(0.85, 1.0)  # Slight squeeze in y direction (1.0 = no squeeze)\n",
    "    \n",
    "    return cx, cy, size, x_squeeze, y_squeeze\n",
    "\n",
    "def apply_random_blur(img):\n",
    "    if random.random() < blur_prob:\n",
    "        ksize = random.choice([3,5,7])\n",
    "        img = cv2.GaussianBlur(img, (ksize,ksize), 0)\n",
    "    if random.random() < 0.15:\n",
    "        # Simulate motion blur\n",
    "        size = random.choice([5,9,15])\n",
    "        kernel_motion_blur = np.zeros((size, size))\n",
    "        kernel_motion_blur[int((size-1)/2), :] = np.ones(size)\n",
    "        kernel_motion_blur = kernel_motion_blur / size\n",
    "        img = cv2.filter2D(img, -1, kernel_motion_blur)\n",
    "    return img\n",
    "\n",
    "def apply_brightness(img):\n",
    "    if random.random() < brightness_jitter:\n",
    "        factor = random.uniform(0.7, 1.3)\n",
    "        pil_img = Image.fromarray(img)\n",
    "        enhancer = ImageEnhance.Brightness(pil_img)\n",
    "        img = np.array(enhancer.enhance(factor))\n",
    "    return img\n",
    "\n",
    "def random_distractor(img):\n",
    "    shape = random.choice([\"circle\",\"triangle\"])\n",
    "    color = tuple(np.random.randint(0,255,3).tolist())\n",
    "    thickness = random.choice([-1,2])\n",
    "    if shape == \"circle\":\n",
    "        cx, cy = random.randint(0,img_size), random.randint(0,img_size)\n",
    "        r = random.randint(15,50)\n",
    "        cv2.circle(img, (cx,cy), r, color, thickness)\n",
    "    elif shape == \"triangle\":\n",
    "        pts = np.random.randint(0,img_size, (3,2))\n",
    "        cv2.polylines(img, [pts], isClosed=True, color=color, thickness=thickness if thickness>0 else 2)\n",
    "        if thickness == -1:\n",
    "            cv2.fillPoly(img, [pts], color)\n",
    "    return img\n",
    "\n",
    "# --- Generation Loop ---\n",
    "print(\"Generating images...\")\n",
    "all_image_paths = []\n",
    "for i in tqdm(range(total_images)):\n",
    "    img = make_background()\n",
    "    label_lines = []\n",
    "    nsq = random.randint(min_squares, max_squares)\n",
    "    used_classes = random.sample(list(colors.keys()), nsq)\n",
    "    for cname in used_classes:\n",
    "        bgr, classid = colors[cname]\n",
    "        cx, cy, size, x_squeeze, y_squeeze = random_square_params()\n",
    "        half = size / 2\n",
    "        \n",
    "        # MODIFIED: Create square with primary x-dimension squeeze and slight y-dimension squeeze\n",
    "        # This simulates more realistic perspective from floor where squares get thinner\n",
    "        # mostly horizontally and slightly vertically\n",
    "        pts = np.array([\n",
    "            [-half * x_squeeze, -half * y_squeeze],  # Top-left - squeezed in x and slightly in y\n",
    "            [half * x_squeeze, -half * y_squeeze],   # Top-right - squeezed in x and slightly in y\n",
    "            [half, half],                           # Bottom-right - normal\n",
    "            [-half, half]                           # Bottom-left - normal\n",
    "        ], dtype=np.float32)\n",
    "        \n",
    "        # Apply random horizontal shear to simulate different viewing angles\n",
    "        if random.random() < 0.7:\n",
    "            shear_factor = random.uniform(-0.3, 0.3)\n",
    "            shear_matrix = np.array([\n",
    "                [1, shear_factor, 0],\n",
    "                [0, 1, 0]\n",
    "            ], dtype=np.float32)\n",
    "            pts = np.dot(pts, shear_matrix[:,:2].T)\n",
    "        \n",
    "        pts += np.array([cx, cy])\n",
    "        pts = pts.astype(np.int32)\n",
    "        cv2.fillConvexPoly(img, pts, bgr)\n",
    "\n",
    "        x_min, y_min = np.min(pts, axis=0)\n",
    "        x_max, y_max = np.max(pts, axis=0)\n",
    "        x_center = ((x_min + x_max) / 2) / img_size\n",
    "        y_center = ((y_min + y_max) / 2) / img_size\n",
    "        w = (x_max - x_min) / img_size\n",
    "        h = (y_max - y_min) / img_size\n",
    "        label_lines.append(f\"{classid} {x_center:.6f} {y_center:.6f} {w:.6f} {h:.6f}\")\n",
    "\n",
    "    # Add distractor shapes\n",
    "    if distractor_shapes and random.random() < 0.5:\n",
    "        n = random.randint(1,3)\n",
    "        for _ in range(n):\n",
    "            img = random_distractor(img)\n",
    "\n",
    "    # Blurring & brightness\n",
    "    img = apply_random_blur(img)\n",
    "    img = apply_brightness(img)\n",
    "\n",
    "    fname = f\"synthetic_{i:05d}.jpg\"\n",
    "    img_path = os.path.join(img_dir, fname)\n",
    "    lbl_path = os.path.join(lbl_dir, fname.replace(\".jpg\", \".txt\"))\n",
    "    cv2.imwrite(img_path, img)\n",
    "    with open(lbl_path, \"w\") as f:\n",
    "        for line in label_lines:\n",
    "            f.write(line + \"\\n\")\n",
    "    all_image_paths.append(img_path)\n",
    "\n",
    "print(\"Dataset generated. Splitting into train/val...\")\n",
    "\n",
    "# --- Train/Val Split ---\n",
    "train_imgs, val_imgs = train_test_split(all_image_paths, test_size=0.15, random_state=42)\n",
    "for split, img_list in [(\"train\", train_imgs), (\"val\", val_imgs)]:\n",
    "    split_img_dir = os.path.join(output_dir, \"images\", split)\n",
    "    split_lbl_dir = os.path.join(output_dir, \"labels\", split)\n",
    "    os.makedirs(split_img_dir, exist_ok=True)\n",
    "    os.makedirs(split_lbl_dir, exist_ok=True)\n",
    "    for img_path in img_list:\n",
    "        base = os.path.basename(img_path)\n",
    "        lbl_path = os.path.join(lbl_dir, base.replace(\".jpg\",\".txt\"))\n",
    "        os.rename(img_path, os.path.join(split_img_dir, base))\n",
    "        os.rename(lbl_path, os.path.join(split_lbl_dir, base.replace(\".jpg\",\".txt\")))\n",
    "\n",
    "print(\"Done! Final structure is:\")\n",
    "print(f\"{output_dir}/images/train/  (images for training)\")\n",
    "print(f\"{output_dir}/images/val/    (images for validation)\")\n",
    "print(f\"{output_dir}/labels/train/  (labels for training)\")\n",
    "print(f\"{output_dir}/labels/val/    (labels for validation)\")\n",
    "\n",
    "# --- YAML for YOLOv8 ---\n",
    "yaml = f\"\"\"\n",
    "path: {os.path.abspath(output_dir)}\n",
    "train: images/train\n",
    "val: images/val\n",
    "nc: {len(colors)}\n",
    "names: {class_names}\n",
    "\"\"\"\n",
    "with open(os.path.join(output_dir, \"data.yaml\"), \"w\") as f:\n",
    "    f.write(yaml)\n",
    "\n",
    "print(\"data.yaml written!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cde7dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG\n",
    "import  os\n",
    "output_dir = \"synthetic_squares\"\n",
    "img_dir = os.path.join(output_dir, \"images\")\n",
    "lbl_dir = os.path.join(output_dir, \"labels\")\n",
    "\n",
    "\n",
    "img_size = 224\n",
    "total_images = 2000           # Total images (across train/val)\n",
    "min_squares = 1\n",
    "max_squares = 3               # Up to N colored squares per image\n",
    "distractor_shapes = True      # Add circles/triangles for difficulty\n",
    "blur_prob = 0.3\n",
    "brightness_jitter = 0.25\n",
    "real_bg_prob = 0.4            # Use real backgrounds X% of the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8dffeee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training YOLOv8n model on synthetic squares dataset\n",
      "Using device: CPU\n",
      "Ultralytics 8.3.141  Python-3.9.18 torch-2.7.0+cpu CPU (AMD Ryzen 9 7950X 16-Core Processor)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=synthetic_squares\\data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs\\detect\\train2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to 'C:\\Users\\fredr\\AppData\\Roaming\\Ultralytics\\Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 755k/755k [00:00<00:00, 9.05MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=6\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752482  ultralytics.nn.modules.head.Detect           [6, [64, 128, 256]]           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary: 129 layers, 3,012,018 parameters, 3,012,002 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 3.32.4 MB/s, size: 13.5 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\fredr\\BTH\\Robotik Project\\Robotics\\21MajFiles\\apa\\synthetic_squares\\labels\\train... 1700 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1700/1700 [00:01<00:00, 1166.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\fredr\\BTH\\Robotik Project\\Robotics\\21MajFiles\\apa\\synthetic_squares\\labels\\train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 5.82.6 MB/s, size: 23.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fredr\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\fredr\\BTH\\Robotik Project\\Robotics\\21MajFiles\\apa\\synthetic_squares\\labels\\val... 300 images, 0 backgrounds, 0 corrupt: 100%|██████████| 300/300 [00:00<00:00, 1106.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\fredr\\BTH\\Robotik Project\\Robotics\\21MajFiles\\apa\\synthetic_squares\\labels\\val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\fredr\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train2\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train2\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50         0G     0.9351      2.757      1.152         10        224: 100%|██████████| 107/107 [00:18<00:00,  5.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.775      0.689      0.791      0.641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50         0G     0.7584      1.092      1.081         14        224: 100%|██████████| 107/107 [00:17<00:00,  6.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.889      0.849      0.914      0.765\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       3/50         0G     0.7228     0.9665      1.073         10        224: 100%|██████████| 107/107 [00:17<00:00,  6.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.914      0.895      0.941      0.811\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       4/50         0G      0.699     0.8908      1.058         14        224: 100%|██████████| 107/107 [00:17<00:00,  6.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.919      0.885      0.943      0.815\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       5/50         0G     0.6505     0.8156      1.037          8        224: 100%|██████████| 107/107 [00:17<00:00,  6.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.957      0.911      0.963      0.852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50         0G     0.6178     0.7478      1.009         18        224: 100%|██████████| 107/107 [00:17<00:00,  6.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.913      0.917      0.956      0.855\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       7/50         0G     0.6097     0.7441      1.011         14        224: 100%|██████████| 107/107 [00:17<00:00,  6.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.959       0.93      0.968      0.854\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       8/50         0G     0.5905     0.7114      1.002         17        224: 100%|██████████| 107/107 [00:17<00:00,  6.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.958      0.937      0.971       0.87\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       9/50         0G     0.5784     0.6577     0.9932         14        224: 100%|██████████| 107/107 [00:16<00:00,  6.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  7.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.962      0.933      0.975      0.878\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      10/50         0G      0.588     0.6526      1.005         10        224: 100%|██████████| 107/107 [00:16<00:00,  6.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.962      0.933      0.974      0.879\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      11/50         0G      0.551     0.6022     0.9848          9        224: 100%|██████████| 107/107 [00:17<00:00,  6.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.972       0.95      0.979      0.885\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      12/50         0G     0.5548      0.607     0.9935         22        224: 100%|██████████| 107/107 [00:18<00:00,  5.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.956      0.928      0.968      0.887\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      13/50         0G     0.5514     0.6086     0.9861          9        224: 100%|██████████| 107/107 [00:16<00:00,  6.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  7.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.972       0.94      0.979      0.907\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      14/50         0G     0.5486     0.5946     0.9853         15        224: 100%|██████████| 107/107 [00:17<00:00,  6.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605       0.97      0.945      0.979      0.907\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      15/50         0G     0.5351     0.5892     0.9727         26        224: 100%|██████████| 107/107 [00:16<00:00,  6.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  7.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.973      0.951      0.979      0.904\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      16/50         0G     0.5217     0.5586      0.959         13        224: 100%|██████████| 107/107 [00:17<00:00,  6.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  7.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.984      0.956      0.981      0.903\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      17/50         0G     0.5104     0.5374     0.9568         18        224: 100%|██████████| 107/107 [00:17<00:00,  6.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.977      0.947       0.98      0.902\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      18/50         0G     0.5088     0.5317     0.9594          9        224: 100%|██████████| 107/107 [00:18<00:00,  5.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.971      0.951      0.977      0.917\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      19/50         0G     0.4988     0.5304     0.9545         17        224: 100%|██████████| 107/107 [00:17<00:00,  6.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  7.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.965      0.945      0.974      0.914\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      20/50         0G     0.4997     0.5353     0.9589         17        224: 100%|██████████| 107/107 [00:17<00:00,  6.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.988      0.937      0.982       0.93\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      21/50         0G     0.4845      0.502     0.9464         11        224: 100%|██████████| 107/107 [00:17<00:00,  6.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605       0.98      0.941      0.981       0.93\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      22/50         0G      0.477     0.4948     0.9414         13        224: 100%|██████████| 107/107 [00:17<00:00,  6.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  7.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605       0.99      0.956      0.983      0.931\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      23/50         0G     0.4723     0.4814     0.9416         12        224: 100%|██████████| 107/107 [00:17<00:00,  6.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  7.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.977      0.961      0.984      0.927\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      24/50         0G      0.479     0.4853     0.9458         18        224: 100%|██████████| 107/107 [00:17<00:00,  6.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  7.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.978      0.956      0.983      0.931\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      25/50         0G     0.4651     0.4824     0.9389         24        224: 100%|██████████| 107/107 [00:17<00:00,  6.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  7.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.984      0.956      0.984      0.931\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      26/50         0G     0.4618     0.4798     0.9383         11        224: 100%|██████████| 107/107 [00:16<00:00,  6.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.987      0.962      0.984      0.937\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      27/50         0G     0.4534     0.4562     0.9298          8        224: 100%|██████████| 107/107 [00:17<00:00,  6.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  7.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.994      0.956      0.985      0.936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/50         0G     0.4478     0.4538     0.9298         17        224: 100%|██████████| 107/107 [00:17<00:00,  6.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.987      0.959      0.984      0.936\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      29/50         0G      0.446     0.4487     0.9315         19        224: 100%|██████████| 107/107 [00:16<00:00,  6.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  7.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.991      0.963      0.985      0.936\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      30/50         0G     0.4476     0.4533      0.928         13        224: 100%|██████████| 107/107 [00:17<00:00,  6.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  7.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.984      0.959      0.985      0.934\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      31/50         0G     0.4383     0.4425     0.9249         17        224: 100%|██████████| 107/107 [00:17<00:00,  6.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.989      0.954      0.986      0.942\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      32/50         0G     0.4499     0.4432     0.9296         26        224: 100%|██████████| 107/107 [00:17<00:00,  6.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  7.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.983      0.964      0.986      0.942\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      33/50         0G     0.4403     0.4367     0.9245         17        224: 100%|██████████| 107/107 [00:17<00:00,  6.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.987      0.962      0.986       0.94\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      34/50         0G     0.4281     0.4263     0.9203         19        224: 100%|██████████| 107/107 [00:17<00:00,  6.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.977      0.966      0.986      0.942\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      35/50         0G     0.4328     0.4345     0.9205         17        224: 100%|██████████| 107/107 [00:17<00:00,  6.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.986      0.966      0.986      0.938\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      36/50         0G     0.4286     0.4168     0.9216         15        224: 100%|██████████| 107/107 [00:17<00:00,  6.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  7.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.984      0.965      0.986      0.943\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      37/50         0G     0.4327     0.4203     0.9255         15        224: 100%|██████████| 107/107 [00:17<00:00,  6.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.981      0.967      0.986      0.944\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      38/50         0G     0.4214     0.4058     0.9201         12        224: 100%|██████████| 107/107 [00:17<00:00,  6.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  7.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.992      0.962      0.986      0.945\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      39/50         0G     0.4225      0.412     0.9237         21        224: 100%|██████████| 107/107 [00:17<00:00,  6.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.993       0.96      0.985       0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/50         0G     0.4134     0.4005     0.9179         17        224: 100%|██████████| 107/107 [00:17<00:00,  6.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  7.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.996      0.955      0.987      0.947\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\fredr\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "      41/50         0G     0.3223      0.321     0.8489          9        224: 100%|██████████| 107/107 [00:17<00:00,  6.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  7.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.984      0.968      0.986      0.944\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      42/50         0G     0.3156     0.3139     0.8478          5        224: 100%|██████████| 107/107 [00:16<00:00,  6.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.987      0.967      0.986      0.949\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      43/50         0G     0.3039     0.3036     0.8417          8        224: 100%|██████████| 107/107 [00:16<00:00,  6.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  7.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605       0.99      0.961      0.986      0.948\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      44/50         0G     0.3044     0.3005     0.8411         11        224: 100%|██████████| 107/107 [00:16<00:00,  6.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.989      0.966      0.987      0.947\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      45/50         0G     0.2968     0.2972     0.8411          8        224: 100%|██████████| 107/107 [00:16<00:00,  6.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605       0.99      0.969      0.986      0.947\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      46/50         0G     0.2968     0.2895     0.8416          9        224: 100%|██████████| 107/107 [00:16<00:00,  6.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  7.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.989      0.974      0.987      0.952\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      47/50         0G     0.2898     0.2803      0.836          8        224: 100%|██████████| 107/107 [00:16<00:00,  6.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.992      0.972      0.987      0.951\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      48/50         0G     0.2821     0.2799     0.8379          7        224: 100%|██████████| 107/107 [00:16<00:00,  6.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.992      0.971      0.987      0.953\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      49/50         0G     0.2842     0.2767     0.8359          7        224: 100%|██████████| 107/107 [00:17<00:00,  6.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.994      0.964      0.987      0.956\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      50/50         0G     0.2809     0.2778     0.8321          8        224: 100%|██████████| 107/107 [00:16<00:00,  6.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  7.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.994      0.965      0.987      0.956\n",
      "\n",
      "50 epochs completed in 0.260 hours.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer stripped from runs\\detect\\train2\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from runs\\detect\\train2\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating runs\\detect\\train2\\weights\\best.pt...\n",
      "Ultralytics 8.3.141  Python-3.9.18 torch-2.7.0+cpu CPU (AMD Ryzen 9 7950X 16-Core Processor)\n",
      "Model summary (fused): 72 layers, 3,006,818 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:01<00:00,  7.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.994      0.964      0.987      0.956\n",
      "                  blue        106        106       0.99      0.955      0.984       0.95\n",
      "                   red        105        105          1      0.988      0.995      0.974\n",
      "                orange        105        105          1      0.957      0.994      0.971\n",
      "                yellow         93         93      0.991          1      0.995      0.968\n",
      "                purple        102        102      0.991      0.931      0.969      0.924\n",
      "                 brown         94         94      0.989      0.954      0.985      0.949\n",
      "Speed: 0.1ms preprocess, 2.6ms inference, 0.0ms loss, 0.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train2\u001b[0m\n",
      "\n",
      "Training complete!\n",
      "Model saved at: runs\\detect\\train2\\weights\\best.pt\n",
      "Ultralytics 8.3.141  Python-3.9.18 torch-2.7.0+cpu CPU (AMD Ryzen 9 7950X 16-Core Processor)\n",
      "Model summary (fused): 72 layers, 3,006,818 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 339.058.8 MB/s, size: 23.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\fredr\\BTH\\Robotik Project\\Robotics\\21MajFiles\\apa\\synthetic_squares\\labels\\val.cache... 300 images, 0 backgrounds, 0 corrupt: 100%|██████████| 300/300 [00:00<?, ?it/s]\n",
      "c:\\Users\\fredr\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 19/19 [00:01<00:00, 13.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300        605      0.994      0.964      0.987      0.956\n",
      "                  blue        106        106       0.99      0.955      0.984       0.95\n",
      "                   red        105        105          1      0.988      0.995      0.974\n",
      "                orange        105        105          1      0.957      0.994      0.971\n",
      "                yellow         93         93      0.991          1      0.995      0.968\n",
      "                purple        102        102      0.991      0.931      0.969      0.924\n",
      "                 brown         94         94      0.989      0.954      0.985      0.949\n",
      "Speed: 0.0ms preprocess, 3.0ms inference, 0.0ms loss, 0.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train22\u001b[0m\n",
      "Validation metrics: mAP@0.5=0.9870, mAP@0.5:0.95=0.9560\n",
      "\n",
      "image 1/1 c:\\Users\\fredr\\BTH\\Robotik Project\\Robotics\\21MajFiles\\apa\\synthetic_squares\\images\\val\\synthetic_00023.jpg: 224x224 1 orange, 12.3ms\n",
      "Speed: 0.5ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Results saved to \u001b[1mruns\\detect\\train23\u001b[0m\n",
      "Inference test complete. Results saved at: runs\\detect\\train23\n"
     ]
    }
   ],
   "source": [
    "# Training YOLOv8 on the synthetic dataset\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Configuration for YOLOv8 training\n",
    "config = {\n",
    "    \"model_size\": \"n\",        # n (nano), s (small), m (medium), l (large), x (xlarge)\n",
    "    \"epochs\": 50,             # Number of training epochs\n",
    "    \"batch_size\": 16,         # Batch size\n",
    "    \"img_size\": img_size,     # Use same image size as generated dataset\n",
    "    \"patience\": 10,           # Early stopping patience\n",
    "    \"device\": 0 if torch.cuda.is_available() else \"cpu\"  # Use GPU if available\n",
    "}\n",
    "\n",
    "print(f\"Training YOLOv8{config['model_size']} model on synthetic squares dataset\")\n",
    "print(f\"Using device: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")\n",
    "\n",
    "# Initialize pre-trained YOLOv8 model\n",
    "model = YOLO(f\"yolov8{config['model_size']}.pt\")\n",
    "\n",
    "# Train the model\n",
    "results = model.train(\n",
    "    data=os.path.join(output_dir, \"data.yaml\"),\n",
    "    epochs=config['epochs'],\n",
    "    imgsz=config['img_size'],\n",
    "    batch=config['batch_size'],\n",
    "    patience=config['patience'],\n",
    "    device=config['device'],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\nTraining complete!\")\n",
    "print(f\"Model saved at: {os.path.join(model.trainer.save_dir, 'weights', 'best.pt')}\")\n",
    "\n",
    "# Validate the model\n",
    "val_results = model.val()\n",
    "print(f\"Validation metrics: mAP@0.5={val_results.box.map50:.4f}, mAP@0.5:0.95={val_results.box.map:.4f}\")\n",
    "\n",
    "# Optional: Run inference on a sample image\n",
    "sample_img = os.path.join(output_dir, \"images\", \"val\", os.listdir(os.path.join(output_dir, \"images\", \"val\"))[0])\n",
    "results = model.predict(source=sample_img, save=True, conf=0.25)\n",
    "print(f\"Inference test complete. Results saved at: {model.predictor.save_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9440d535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 224x224 (no detections), 8.5ms\n",
      "Speed: 1.3ms preprocess, 8.5ms inference, 0.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 (no detections), 8.3ms\n",
      "Speed: 0.8ms preprocess, 8.3ms inference, 0.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 1 brown, 8.8ms\n",
      "Speed: 0.4ms preprocess, 8.8ms inference, 0.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 (no detections), 8.8ms\n",
      "Speed: 0.4ms preprocess, 8.8ms inference, 0.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 (no detections), 8.7ms\n",
      "Speed: 0.3ms preprocess, 8.7ms inference, 0.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 (no detections), 8.3ms\n",
      "Speed: 0.4ms preprocess, 8.3ms inference, 0.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 (no detections), 8.0ms\n",
      "Speed: 0.5ms preprocess, 8.0ms inference, 0.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 (no detections), 8.4ms\n",
      "Speed: 0.5ms preprocess, 8.4ms inference, 0.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 (no detections), 9.2ms\n",
      "Speed: 0.4ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 1 blue, 8.8ms\n",
      "Speed: 0.2ms preprocess, 8.8ms inference, 0.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 (no detections), 7.9ms\n",
      "Speed: 0.4ms preprocess, 7.9ms inference, 0.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 (no detections), 7.3ms\n",
      "Speed: 0.3ms preprocess, 7.3ms inference, 0.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 (no detections), 8.2ms\n",
      "Speed: 0.4ms preprocess, 8.2ms inference, 0.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 1 brown, 7.3ms\n",
      "Speed: 0.4ms preprocess, 7.3ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 (no detections), 6.8ms\n",
      "Speed: 0.4ms preprocess, 6.8ms inference, 0.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 (no detections), 8.0ms\n",
      "Speed: 0.3ms preprocess, 8.0ms inference, 0.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 1 blue, 8.6ms\n",
      "Speed: 0.5ms preprocess, 8.6ms inference, 0.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 1 orange, 10.5ms\n",
      "Speed: 0.3ms preprocess, 10.5ms inference, 0.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 (no detections), 8.1ms\n",
      "Speed: 0.3ms preprocess, 8.1ms inference, 0.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 1 brown, 8.0ms\n",
      "Speed: 0.4ms preprocess, 8.0ms inference, 0.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 (no detections), 8.0ms\n",
      "Speed: 0.3ms preprocess, 8.0ms inference, 0.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 (no detections), 8.0ms\n",
      "Speed: 0.2ms preprocess, 8.0ms inference, 0.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 (no detections), 8.6ms\n",
      "Speed: 0.3ms preprocess, 8.6ms inference, 0.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 (no detections), 8.5ms\n",
      "Speed: 0.4ms preprocess, 8.5ms inference, 0.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 1 blue, 7.7ms\n",
      "Speed: 0.4ms preprocess, 7.7ms inference, 0.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 (no detections), 7.9ms\n",
      "Speed: 0.3ms preprocess, 7.9ms inference, 0.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 (no detections), 8.3ms\n",
      "Speed: 0.4ms preprocess, 8.3ms inference, 0.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 (no detections), 6.4ms\n",
      "Speed: 0.3ms preprocess, 6.4ms inference, 0.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 1 blue, 7.9ms\n",
      "Speed: 0.4ms preprocess, 7.9ms inference, 0.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 1 blue, 7.6ms\n",
      "Speed: 0.3ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 1 blue, 9.0ms\n",
      "Speed: 0.3ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 1 blue, 8.1ms\n",
      "Speed: 0.5ms preprocess, 8.1ms inference, 0.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 (no detections), 7.8ms\n",
      "Speed: 0.3ms preprocess, 7.8ms inference, 0.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 (no detections), 8.8ms\n",
      "Speed: 0.4ms preprocess, 8.8ms inference, 0.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 1 red, 1 brown, 7.5ms\n",
      "Speed: 0.2ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 (no detections), 8.1ms\n",
      "Speed: 0.4ms preprocess, 8.1ms inference, 0.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 (no detections), 8.4ms\n",
      "Speed: 0.5ms preprocess, 8.4ms inference, 0.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 (no detections), 10.1ms\n",
      "Speed: 0.4ms preprocess, 10.1ms inference, 0.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 1 blue, 8.0ms\n",
      "Speed: 0.5ms preprocess, 8.0ms inference, 0.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 1 blue, 1 red, 7.6ms\n",
      "Speed: 0.4ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 (no detections), 8.0ms\n",
      "Speed: 0.4ms preprocess, 8.0ms inference, 0.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 1 yellow, 8.0ms\n",
      "Speed: 0.3ms preprocess, 8.0ms inference, 0.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 1 yellow, 7.3ms\n",
      "Speed: 0.4ms preprocess, 7.3ms inference, 0.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 1 yellow, 8.1ms\n",
      "Speed: 0.4ms preprocess, 8.1ms inference, 0.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 (no detections), 8.2ms\n",
      "Speed: 0.6ms preprocess, 8.2ms inference, 0.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 1 yellow, 10.4ms\n",
      "Speed: 0.5ms preprocess, 10.4ms inference, 0.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 (no detections), 8.7ms\n",
      "Speed: 0.4ms preprocess, 8.7ms inference, 0.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 1 yellow, 7.6ms\n",
      "Speed: 0.2ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 1 orange, 1 yellow, 7.3ms\n",
      "Speed: 0.3ms preprocess, 7.3ms inference, 0.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 1 yellow, 8.0ms\n",
      "Speed: 0.4ms preprocess, 8.0ms inference, 0.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 1 yellow, 7.2ms\n",
      "Speed: 0.3ms preprocess, 7.2ms inference, 0.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 (no detections), 7.8ms\n",
      "Speed: 0.4ms preprocess, 7.8ms inference, 0.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 1 yellow, 7.9ms\n",
      "Speed: 0.4ms preprocess, 7.9ms inference, 0.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 (no detections), 7.4ms\n",
      "Speed: 0.3ms preprocess, 7.4ms inference, 0.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 (no detections), 8.1ms\n",
      "Speed: 0.4ms preprocess, 8.1ms inference, 0.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 1 yellow, 8.2ms\n",
      "Speed: 0.4ms preprocess, 8.2ms inference, 0.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 1 yellow, 9.3ms\n",
      "Speed: 0.3ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 1 yellow, 8.3ms\n",
      "Speed: 0.4ms preprocess, 8.3ms inference, 0.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 (no detections), 7.9ms\n",
      "Speed: 0.4ms preprocess, 7.9ms inference, 0.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 (no detections), 8.5ms\n",
      "Speed: 0.2ms preprocess, 8.5ms inference, 0.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Done! Annotated images saved to: C:\\Users\\fredr\\BTH\\Robotik Project\\Robotics\\yolo_dataset\\images\\train_annotated\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# === Paths ===\n",
    "model_path = r\"runs\\detect\\train2\\weights\\best.pt\"\n",
    "image_dir = r\"C:\\Users\\fredr\\BTH\\Robotik Project\\Robotics\\yolo_dataset\\images\\train\"\n",
    "output_dir = r\"C:\\Users\\fredr\\BTH\\Robotik Project\\Robotics\\yolo_dataset\\images\\train_annotated\"\n",
    "\n",
    "# === Create output directory if it doesn't exist ===\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# === Load model ===\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# === Inference on all images ===\n",
    "image_extensions = ('.jpg', '.jpeg', '.png')\n",
    "for filename in os.listdir(image_dir):\n",
    "    if filename.lower().endswith(image_extensions):\n",
    "        image_path = os.path.join(image_dir, filename)\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # Run inference\n",
    "        results = model(image)[0]\n",
    "\n",
    "        # Draw bounding boxes\n",
    "        for box in results.boxes:\n",
    "            cls_id = int(box.cls[0])\n",
    "            conf = float(box.conf[0])\n",
    "            label = model.names[cls_id]\n",
    "\n",
    "            # Get bounding box coordinates\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            color = (0, 255, 0)  # Green box\n",
    "            cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
    "            text = f\"{label} {conf:.2f}\"\n",
    "            cv2.putText(image, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "\n",
    "        # Save annotated image\n",
    "        out_path = os.path.join(output_dir, filename)\n",
    "        cv2.imwrite(out_path, image)\n",
    "\n",
    "print(f\"Done! Annotated images saved to: {output_dir}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
